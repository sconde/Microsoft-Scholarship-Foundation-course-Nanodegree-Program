Scaling Data
============

**Scaling** data means transforming it so that the values fit within some range or scale, such as 0â€“100 or 0â€“1. There are a number of reasons why it is a good idea to scale your data before feeding it into a machine learning algorithm.

Let's consider an example. Imagine you have an image represented as a set of RGB values ranging from 0 to 255. We can scale the range of the values from 0â€“255 down to a range of 0â€“1. This scaling process will not affect the algorithm output since every value is scaled in the same way. But it can speed up the training process, because now the algorithm only needs to handle numbers less than or equal to 1.

Two common approaches to scaling data include **standardization** and **normalization**.

Standardization
---------------

> **Standardization** rescales data so that it has a mean of 0 and a standard deviation of 1.

The formula for this is:

> (ð‘¥ âˆ’ ðœ‡)/ðœŽ

We subtract the mean (ðœ‡) from each value (x) and then divide by the standard deviation (ðœŽ). To understand why this works, it helps to look at an example. Suppose that we have a sample that contains three data points with the following values:

    50  
    100  
    150  
    

The mean of our data would be `100`, while the sample standard deviation would be `50`.

Let's try standardizing each of these data points. The calculations are:

    (50 âˆ’ 100)/50 = -50/50 = -1
    (100 âˆ’ 100)/50 = 0/50 = 0
    (150 âˆ’ 100)/50 = 50/50 = 1
    

Thus, our transformed data points are:

    -1  
    0  
    1
    

Again, the result of the standardization is that our data distribution now has a mean of 0 and a standard deviation of 1.

Normalization
-------------

> **Normalization** rescales the data into the range \[0, 1\].

The formula for this is:

> (ð‘¥ âˆ’ð‘¥ð‘šð‘–ð‘›)/(ð‘¥ð‘šð‘Žð‘¥ âˆ’ð‘¥ð‘šð‘–ð‘›)

For each individual value, you subtract the minimum value (ð‘¥ð‘šð‘–ð‘›) for that input in the training dataset, and then divide by the range of the values in the training dataset. The range of the values is the difference between the maximum value (ð‘¥ð‘šð‘Žð‘¥) and the minimum value (ð‘¥ð‘šð‘–ð‘›).

Let's try working through an example with those same three data points:

    50  
    100  
    150  
    

The minimum value (ð‘¥ð‘šð‘–ð‘›) is `50`, while the maximum value (ð‘¥ð‘šð‘Žð‘¥) is `150`. The range of the values is ð‘¥ð‘šð‘Žð‘¥ âˆ’ð‘¥ð‘šð‘–ð‘› = 150 âˆ’ 50 = 100.

Plugging everything into the formula, we get:

    (50 âˆ’ 50)/100 = 0/100 = 0
    (100 âˆ’ 50)/100 = 50/100 = 0.5
    (150 âˆ’ 50)/100 = 100/100 = 1
    

Thus, our transformed data points are:

    0
    0.5  
    1
    

Again, the goal was to rescale our data into values ranging from 0 to 1â€”and as you can see, that's exactly what the formula did.

### Question 1 of 3

Which of the below refers to **standardization** and which refers to **normalization**?
Standardization or normalization?

Standardization: 
Rescales the data to have mean = 0 and standard deviation = 1

Normalization:
Rescales the data into the range \[0, 1\]

Normalization: 
(ð‘¥ âˆ’ð‘¥ð‘šð‘–ð‘›)/(ð‘¥ð‘šð‘Žð‘¥ âˆ’ð‘¥ð‘šð‘–ð‘›)

Standardization: 
(ð‘¥ âˆ’ ðœ‡)/ðœŽ


Standardize -5,10,15. Knowing that the mean is 7 and the standard deviation is 10. Use commas to separate numbers and keep one decimal place (e.g. 1.0,2.3,3.0 or -1.5,1.1,2.4)

> -1.2,0.3,0.8


Normalize -5,10,15. Knowing that the mean is 7 and the standard deviation is 10. Use commas to separate numbers and keep one decimal place (e.g. 1.0,2.3,3.0 or -1.5,1.1,2.4)

> 0    0.7500    1.0000

